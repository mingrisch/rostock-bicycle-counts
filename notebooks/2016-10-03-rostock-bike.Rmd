---
title: "Bike usage in Rostock"
author: "Michael Ingrisch"
date: "October 3, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Bike usage in Rostock

In this project, we analyze data from bicycle counters in Rostock, Germany. Data is kindly provided in open form from several counters in Rostock, via the web site http://www.opendata-hro.de/dataset/radmonitore

Not being familiar with this city, we choose (rather arbitrarily) a single bike counter in the center.

Importantly, in this project, we follow the recently published book "R for data science", in order to get familiar with the suite of packages commonly referred to as "tidyverse"

This document is written in R markdown, in order to provide maximal reproducibility.

# Prerequisites

Before starting out with the analysis, the following list of packages was installed:
```{r prerequisites, eval=FALSE, include=FALSE}
pkgs <- c(
  "dplyr", "gapminder", "ggplot2", "jsonlite", "Lahman", 
  "lubridate", "modelr", "nycflights13", "purrr", "readr", 
  "stringr", "tibble", "tidyr"
)
install.packages(pkgs)
```
Presumably, we could have shortened this by simply installing `tidyverse`.
```{r imports}
library(tidyverse)
```

I am working on an Ubuntu 16.04 system. Installing these packages was not as straightforward as expected, I had to install several system packages manually. Thankfully, the error messages during installation provided all required information.

# Data download and preparation


Data was downloaded from the Rostock open data website on 2016-10-03, as follows:
```{r datadownload}
#library(readr)
# to increase speed, we load locally, instead of
#data <- read_csv('https://geo.sv.rostock.de/download/opendata/radmonitore/radmonitore_daten.csv')
data <- read_csv('data/external/radmonitore_daten.csv')

#data.radmonitore <- read_csv('https://geo.sv.rostock.de/download/opendata/radmonitore/radmonitore_standorte.csv')
data.radmonitore <- read_csv('data/external/radmonitore_standorte.csv')
data
```
This particular dataset contains count data from a range of bicycle counters. For each counter, the number of bikes per 15 minutes is provided. The data consists of three rows, with a total of `r dim(data)[1]` observations.

Detailed data about each bicycle counter is provided in the data frame/tibble data.radmonitore. In particular, we can use the `id` in this dataframe to map the name to the name `bezeichnung`. We select the columns `id` and `bezeichnung` from rad.monitore and join the resulting tibble to the tibble `data`. Then, we dump the then redundant column `id`. 

We can use as simple _mutating join_:

```{r data.join}
id.bezeichung <- data.radmonitore %>% 
  select(id, bezeichnung) %>%
  rename(standort_id=id)

data <- data %>% left_join(id.bezeichung, by = "standort_id") %>%
  select(-standort_id)
```


The data is actually quite tidy:

* each row contains a single observation: the bicycle count in a time window of 15 minutes for a particular counter

* each column contains a single variable: counter, time and count
 
The tibble printout shows that the time (zeitpunkt) already was read as datetime.
We only need to convert the counter name (`bezeichung`)  to a factor.
```{r tidydata}
library(forcats)
library(lubridate)
data <- data %>%
  mutate(bezeichnung = factor(bezeichnung))
 
data %>% count(bezeichnung)   
```

Counting the occurences of each `bezeichnung` reveals that we have data from eight counters with variable number of total observations.

 
# Exploratory data analysis
Before we start to further explore this datset, we split our data, in order to have untouched data for testing possible predictive models in a later stage.

Since we have a large amount of data available, we decide to use data up to 31.12.2014 for exploration and model building, and all later data for testing.

```{r train-test-split}

train <- data%>% filter(year(zeitpunkt)<2015)
test <- data %>% filter(year(zeitpunkt)>=2015)
```
For all further explorations, we hold out the `test` data and use exclusively the `train` data

### Bicycle counts over time

Without any further information, we begin to explore this dataset, using the tidyverse stack. This is a very simple plot, that displays 15-minute counts over the entire time range

```{r EDA1, eval=FALSE}
library(ggplot2)
ggplot(train, aes(zeitpunkt, summe)) +
  geom_line() 

#  facet_wrap(~standort_id,scales='free_y')

```

This plot is rather cluttered. Still, we are able to observe:

* strong seasonal changes: In summer, far more cyclists pass the counters than in winter
* several very strong peaks, which require further investigation
* a steep increase in counts around April 2013 (were further counters installed here?)

### Counts by counting stations

We adress the last observation first and split the plot by counters
```{r EDA2, eval=FALSE}
ggplot(train, aes(zeitpunkt, summe)) +
  geom_line() +
  facet_wrap(~bezeichnung)

```

This shows that the steep increase around April 2014 occurs in all counters that were operating at this time and may hence be associated with other influence factors (weather).

To simplify our further analysis, we focus our analysis on the single counter with the most counts:


```{r EDA.one.counter}
train <- train %>% 
  filter(bezeichnung == 'Am Strande/Holzhalbinsel')
```

We now have restricted our dataset to a single counter. 

```{r EDA3}
ggplot(train, aes(zeitpunkt, summe)) +
  geom_line() 
```

That looks much better. We still observe:
* seasonal changes
* occasional peaks
* periods with no (or very few) counts

### Weekday usage patterns

What is the variation over the weekdays? We first count the number of bicycles per day, and then visualize the counts per weekday:

```{r EDA.weekdays}

daily <- train %>% 
  mutate(date = date(zeitpunkt)) %>%
  group_by(bezeichnung, date) %>% 
  summarise(n = sum(summe)) %>%
  mutate(weekday = wday(date, label = TRUE)) 

daily

ggplot(daily, aes(x=weekday, y=n)) +
  geom_boxplot() 
```

We observe that  Saturday and Sunday generally sees less cyclists than workdays and suggests that moreRostockers often bike to work 

### Usage patterns over daytime

The distribution of counts over the daytime may further elucidate this observation:

```{r EDA.hours, message=FALSE}

hourly <- train %>% 
  mutate(hour = hour(zeitpunkt)) %>%
  group_by(bezeichnung, hour) %>% 
  summarise(mean = mean(summe)) 

hourly

ggplot(hourly, aes(x=hour, y=mean)) +
  geom_line() 


```

## Fixing incorrect datetimes

We observe a bimodal distribution with peaks in counters at 5 am and 15pm, possibly related to school kids and commuters.
This is puzzling: Should those peaks not be more around 8ish and 6ish? I find it hard to believe that Rostockians work so early.

Are we having an issue with timezones and lubridate, maybe? 
A close look at the raw data reveals two key points:

1. The acquisition time starts at 2013-01-01
2. on 2013-04-01, a switch to daylight saving time occurs, indicated by the switch from the +01 offset to +02: 
```
standort_id,zeitpunkt,summe
100005392,2013-01-01T00:00:00+01:00,0
100005392,2013-01-01T00:15:00+01:00,0
...
100005392,2013-03-30T23:45:00+01:00,0
100005392,2013-04-01T00:00:00+02:00,0
```

We investigate our hourly data frame for these dates, to check whether the time column was parsed correctly:
```{r check.time.parsing}
train

filter(train, (zeitpunkt >= as.Date('2013-03-31')) & (zeitpunkt <= as.Date('2013-04-02')))
```

This reveals an issue with our date time parsing. Damn.
It appears that read_csv did not parse the time shift encoded as +01:00 or +02:00 correctly. 

The vignette of readr `vignette("column-types")` reveals that we can specify the format of the `zeitpunkt` column using col_datetime.

Also, `parse_datetime` from the same package allows quick parsing of strings for rapid testing. 

```{r test.time.parsing} 
parse_datetime('2013-01-01T00:00:00+01:00')
parse_datetime('2013-01-01T00:00:00+01:00',locale=locale(tz="Europe/Berlin"))
```

Apparently, providing the correct timezone (found from `OlsonNames`) corrects this issue.

Data preparation all over again, quickly, with a quick look at the commute pattern:

```{r data.preparation.repaired}
data <- read_csv('data/external/radmonitore_daten.csv',
                 locale = locale(tz="Europe/Berlin"))

id.bezeichung <- data.radmonitore %>% 
  select(id, bezeichnung) %>%
  rename(standort_id=id)

data <- data %>% left_join(id.bezeichung, by = "standort_id") %>%
  select(-standort_id) %>%
  mutate(bezeichnung = factor(bezeichnung)) %>%
  filter(bezeichnung == 'Am Strande/Holzhalbinsel')

train <- data%>% filter(year(zeitpunkt)<2015)
test <- data %>% filter(year(zeitpunkt)>=2015)

daily <- train %>% 
  mutate(date = date(zeitpunkt)) %>%
  group_by(bezeichnung, date) %>% 
  summarise(n = sum(summe)) %>%
  mutate(weekday = wday(date, label = TRUE)) 

hourly <- train %>% 
  mutate(hour = hour(zeitpunkt)) %>%
  group_by(bezeichnung, hour) %>% 
  summarise(mean = mean(summe)) 

ggplot(hourly, aes(x=hour, y=mean)) +
  geom_line() +
  scale_x_continuous(breaks=seq(0,23,1), minor_breaks = NULL)
```

This looks much better: the two peaks are sharper now, and, in particular, the occur at sensible daytimes of 7am and 4pm.


# Regression: Modeling the count data

From our exploratory data analysis, we know that our count data is dominated by three main effects:

* seasonal changes: during summertime, we observe a lot more cyclists 

* changes over weekdays: on sundays, we observe reduced bike usage

* changes over daytime: several counters show a bimodal distribution of bicycle counts


In this section, we try to capture these observations in a regression model, starting with the most obvious effect of seasonal changes.

In order to keep things simple, we further reduce our data set to the single counter with the most counts ('Am Strande/Holzhalbinsel').

## Modeling the seasonal changes

We can use two well-known effects of summer for capturing the increase in bikers during the summer months:

* It is warmer
* The sun shines longer

Obviously, the two effects are strongly correlated. However, appropriate data is not available in the original dataframe. Whereas the sunshine time is easier to access, we can also try to capture weather data - this has the additional benefit of providing precipitation data for the observed time - and it is not unlikely that rain has a strong effect on bike counts.

### Accessing weather data from DWD

The closest weather station from the DWD is presumably `04271 19911101 20161002 4 54.1803   12.0808 Rostock-Warnem√ºnde Mecklenburg-Vorpommern `,  as revealed by the list of weather stations provided at ftp://ftp-cdc.dwd.de/pub/CDC/help/EB_Stundenwerte_Beschreibung_Stationen.txt, where the first number is the station id .

Data for  this weather station was downloaded from ftp://ftp-cdc.dwd.de/pub/CDC/observations_germany/climate/daily/kl/historical/tageswerte_04271_19470101_20151231_hist.zip on 2016-10-04.

This zip file contains, along with descriptions, the central datafile `data/external/dwd_rostock. With annoying whitespaces, delimited by `;` and an unparsed date. No problem for readr.

```{r join.weather}
weather <- read_delim('data/external/dwd_rostock/produkt_klima_Tageswerte_19470101_20151231_04271.txt',';', trim_ws = TRUE)

weather$datum <- ymd(weather$`MESS_DATUM`)
weather <- weather %>%
  select(datum, LUFTTEMPERATUR, LUFTTEMPERATUR_MAXIMUM, LUFTTEMPERATUR_MINIMUM)

train$datum <- as_date(train$zeitpunkt)
train.weather <- train %>% left_join(weather, by="datum")
```

 For a start, we visualize the temperature over the time and model the number of cyclists in dependence of the temperature ('LUFTTEMPERATUR').

```{r model.seasonal}
ggplot(train.weather, aes(x=LUFTTEMPERATUR, y=summe)) + geom_hex(bins=50)

train.weather2 <- train.weather %>%
  filter(summe<100) 

ggplot(train.weather2, aes(x=LUFTTEMPERATUR, y=summe)) + 
  geom_hex(bins=50) +


#ggplot(train.weather, aes(zeitpunkt, LUFTTEMPERATUR)) + geom_line()

# how can we display lufttemperatur and summe in facets?

library(modelr)
model.season <- lm(summe~ LUFTTEMPERATUR, data = train.weather2)

# and overlay the model fit
grid <- train.weather%>%
  data_grid(LUFTTEMPERATUR) %>%
  add_predictions((model.season), "summe")

ggplot(train.weather2, aes(x=LUFTTEMPERATUR, y=summe)) +
  geom_hex(bins=50) +
  geom_line(data=grid, color="red")

train.weather <- train.weather %>%
  add_residuals(model.season)

ggplot(train.weather, aes(zeitpunkt, resid)) +
  geom_line()
# better: plot the residuals
```

Fitting a linear model on the temparature has removed the seasonal increase. But also, it appears that the variability of counts is much larger during the summer time. Is this an effect of precipitation? Or wind? One would expect that warm weather does not increase the number of cyclist, when it is raining...

```{r model.seasonal}
ggplot(train.weather, aes(zeitpunkt, NIEDERSCHLAGSHOEHE)) + geom_line()

# how can we display lufttemperatur and summe in facets?

library(modelr)
model.season <- lm(summe~ LUFTTEMPERATUR, data = train.weather)


grid <- train.weather%>%
  data_grid(LUFTTEMPERATUR, zeitpunkt) %>%
  add_predictions((model.season))

# bad idea: memory hog
ggplot(train.weather, aes(zeitpunkt, summe))+
  geom_line() +
  geom_line(aes(y=pred),data = grid, colour="red")

train.weather <- train.weather %>%
  add_residuals(model.season)

ggplot(train.weather, aes(zeitpunkt, resid)) +
  geom_line()
# better: plot the residuals
```
