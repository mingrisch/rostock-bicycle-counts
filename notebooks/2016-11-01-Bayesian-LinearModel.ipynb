{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling bicycle counts: A Bayesian approach\n",
    "\n",
    "In a previous post (add link), we have joined the Rostock bicycle counter data with weather data and public holidays. We have built a  basic linear model that explained our data rather reasonably -- apart from some outliers, which could be associated e.g. with the Hansa Sail Regatta, or public holidays like Christmas). This model was also able to predict cyclist counts on unseen data (from 2016, in our case).\n",
    "\n",
    "This linear model was not only able to describe cyclist counts over the course of the year, but also allowed deducing e.g. how temperature or sunshine time affected cyclist counts: the trained model revealed an increase in daily cyclists counts by XX for each degree of temperature increase.\n",
    "\n",
    "A conventional linear model, such as we used in this previous post, does not allow for a straightforward estimation of parameter uncertainty. In fact, it yields a point estimate, such as an increase of 80 per degree temperature increase. Often, one would like to know not only a point estimate, but also an estimate of the precision of this estimate - or, even better, the whole distribution of that parameter that likely produced the observed data.\n",
    "\n",
    "Recently, a whole branch of statistics allowing precisely this estimation of underlying parameter distributions  has emerged and gained considerable traction. This branch of statistics is commonly referred to as 'Bayesian statistics'. This is not the place to provide an introduction into Bayesian reasoning, instead, I point the interested reader e.g. to a series of blog posts by Jake van der Plas (http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/) , or to an introductory textbook by John Kruschke (https://sites.google.com/site/doingbayesiandataanalysis/).\n",
    "\n",
    "In the following, we use a Bayesian approach to estimate the distributions (or the uncertainty) of the parameters in a linear model explaining cyclist counts in Rostock downtown. We use the same data and the same linear model as in the previous post, and we switch from R to python, in order to use the excellent pymc3 library (https://pymc-devs.github.io/pymc3/notebooks/getting_started.html).\n",
    "\n",
    "This post is written in a jupyter notebook, using anaconda python 2.7.12.\n",
    "\n",
    "## Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import pymc3 as pm\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 712 entries, 2013-01-01 to 2014-12-31\n",
      "Data columns (total 5 columns):\n",
      "n               712 non-null int64\n",
      "temperature     712 non-null float64\n",
      "sunshinetime    649 non-null float64\n",
      "rainy_day       712 non-null bool\n",
      "workday         712 non-null bool\n",
      "dtypes: bool(2), float64(2), int64(1)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "daily = pd.read_csv('../data/processed/train.daily.csv', index_col='date',\n",
    "                   parse_dates = True)\n",
    "\n",
    "# we introduce the long-awaited 'work day' column\n",
    "daily['workday'] =(daily.index.dayofweek<5) & ~daily.holiday\n",
    "\n",
    "# and we dump all columns which we do not need:\n",
    "daily.drop(['weekday','precipitation', 'Feiertage', 'holiday'], axis = 1, inplace = True)\n",
    "\n",
    "daily.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied log-transform to sd and added transformed sd_log_ to model.\n",
      "Assigned NUTS to Intercept\n",
      "Assigned NUTS to temperature\n",
      "Assigned NUTS to sunshinetime\n",
      "Assigned NUTS to sd_log_\n",
      "  2%|â–‹                                        | 77/5000 [11:10<43:38:58, 31.92s/it]"
     ]
    }
   ],
   "source": [
    "from pymc3 import Model, sample\n",
    "\n",
    "from pymc3.glm import glm\n",
    "\n",
    "with Model() as model_glm:\n",
    "    glm('n ~ temperature + sunshinetime', daily)\n",
    "    trace = sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applied log-transform to sigma and added transformed sigma_log_ to model.\n",
      "Assigned NUTS to temperature\n",
      "Assigned NUTS to sunshinetime\n",
      "Assigned NUTS to sigma_log_\n",
      "Assigned Metropolis to intercept\n",
      "Assigned Metropolis to cyclist count\n",
      "  0%|                                                     | 0/2000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# this is silly. we define our model properly:\n",
    "from pymc3 import Model, sample, Poisson, Normal, HalfNormal,find_MAP\n",
    "with Model() as model:\n",
    "    temperature = Normal('temperature', mu = 0, sd =100) # uninformative # or informative?\n",
    "    sunshinetime = Normal('sunshinetime', mu = 0, sd =100) # more sunshinetime equals more cyclists, right=\n",
    "    sigma = HalfNormal('sigma', sd = 100)\n",
    "    intercept= Poisson('intercept', mu = 10)\n",
    "    expected_count = Poisson('cyclist count', \n",
    "                             intercept + temperature + sunshinetime)\n",
    "    count_observed = Poisson('observed count', \n",
    "                             mu = expected_count,\n",
    "                            observed = daily.n)\n",
    "    start = find_MAP()\n",
    "\n",
    "    # draw 2000 posterior samples\n",
    "    trace = sample(2000, start=start)\n",
    "Poisson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
